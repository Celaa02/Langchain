{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6fd1a9-36f1-4bf0-af67-c15f6b55e944",
   "metadata": {},
   "source": [
    "View PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16573aad",
   "metadata": {},
   "source": [
    "The following code allows the reading of a PDF file and makes it easier to obtain information from it, by asking questions through a chat (Chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c36871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204794fa",
   "metadata": {},
   "source": [
    "The loading and reading of the file is defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ef6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file):\n",
    "    name, ext = os.path.splitext(file)\n",
    "    if ext == \".pdf\":\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif ext == \".docx\":\n",
    "        print(f'Loader {file}...')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print('The type file is not support')\n",
    "        return None\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354e4ef-6bad-4634-ab19-4bb9c2e5bbde",
   "metadata": {},
   "source": [
    "the file variable is loaded with the value of the file in the function that performs the identification and reading of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f0658a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/macbook/Desktop/testPython/cultura_colombiana.pdf'\n",
    "data_file = load_file(file)\n",
    "#print(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d03cca-03ca-40e1-9e82-565a79a3ec89",
   "metadata": {},
   "source": [
    "We obtain the number of pages or resulting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f64c633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"text=\"\"\n",
    "for page in data_file.pages:\n",
    "    text += page.extract_text()\"\"\"\n",
    "len(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2af3d-04f4-4f46-b0ec-7682be915e7f",
   "metadata": {},
   "source": [
    "Create Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426b32f-9d96-4cf9-b084-b4619910d6ab",
   "metadata": {},
   "source": [
    "we divide the texts into different Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b473a2-015a-4890-a0e4-1c49503f0d3e",
   "metadata": {},
   "source": [
    "We try to divide at paragraph level, then at sentence level and finally at word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1838f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2181971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = text_splitter.split_documents(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346fea0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1281fd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='cuando escucha hablar de la di-versidad étnica y', metadata={'source': '/Users/macbook/Desktop/testPython/cultura_colombiana.pdf', 'page': 0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14c747-8a05-4beb-bf6b-254b34bda233",
   "metadata": {},
   "source": [
    "Create Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c109e80-5692-4dcd-93aa-2f2efb27e5b8",
   "metadata": {},
   "source": [
    "sentences are converted into numerical values so that they can be interpreted by the computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde8ca9-dc87-454f-9d38-498a4495da5d",
   "metadata": {},
   "source": [
    "use model_name \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba3c02b-bc78-43d3-b810-e223252f7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0045a48-556d-4754-ac6a-5ae5eea9ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n",
      ") model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42c068-82c8-4978-8428-6492723d7386",
   "metadata": {},
   "source": [
    "embeddings of the documents obtained are created  and save to a local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27635ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowlledge_base = FAISS.from_documents(chunk, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b3339-37c4-4cbb-8b5e-c9fc86b56fa9",
   "metadata": {},
   "source": [
    "the question is assigned to a variable and the 3 paragraphs of the pdf that are most similar to the question are searched to provide an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e62fcb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"cuantas copas del mundo ha ganado colombia?\"\n",
    "docs = knowlledge_base.similarity_search(query, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3042305d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Colombia . Tercer Mundo-Departa-', metadata={'source': '/Users/macbook/Desktop/testPython/cultura_colombiana.pdf', 'page': 7}),\n",
       " Document(page_content='Colombiaocupa, después de Brasil, el se-gundo', metadata={'source': '/Users/macbook/Desktop/testPython/cultura_colombiana.pdf', 'page': 0}),\n",
       " Document(page_content='en Colombia, en el cualseñala las diferencias', metadata={'source': '/Users/macbook/Desktop/testPython/cultura_colombiana.pdf', 'page': 4})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76d7de-d4ba-4de3-a577-b1eac8824970",
   "metadata": {},
   "source": [
    "the obtained variables are passed to openai so that it does not return the answers according to the document: \n",
    "\n",
    "we pass the initially the api_key, \n",
    "the model, \n",
    "the documents and the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbacb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', api_key=\"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\")\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0adc6a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/testPython/testlang/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta ChatGPT: No sé.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(input_documents=docs, question=query)\n",
    "print(f\"Respuesta ChatGPT: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d75af6-09a5-4561-9c8b-e16227452061",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "app.py is a file containing the user interface with the code functionality explained above, when opened you will be able to test it very easily.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c482a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.1.8:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "/Users/macbook/Desktop/testPython/testlang/lib/python3.11/site-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.embeddings import HuggingFaceEmbeddings`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "/Users/macbook/Desktop/testPython/testlang/lib/python3.11/site-packages/langchain/vectorstores/__init__.py:35: LangChainDeprecationWarning: Importing vector stores from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.vectorstores import FAISS`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "/Users/macbook/Desktop/testPython/testlang/lib/python3.11/site-packages/langchain/chat_models/__init__.py:31: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "/Users/macbook/Desktop/testPython/testlang/lib/python3.11/site-packages/langchain/document_loaders/__init__.py:36: LangChainDeprecationWarning: Importing document loaders from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.document_loaders import PyPDFLoader`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "/Users/macbook/Desktop/testPython/testlang/lib/python3.11/site-packages/langchain/document_loaders/__init__.py:36: LangChainDeprecationWarning: Importing document loaders from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.document_loaders import Docx2txtLoader`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
